# -*- coding: utf-8 -*-
"""Day 6 Scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12yTuCG2XjT9K26_Wti9eLW54pXmtPi1y
"""

import http.client
import json

conn = http.client.HTTPSConnection("gorest.co.in")
payload = ''
headers = {
  'Accept': 'application/json',
  'Content-Type': 'application/json',
  'Authorization': 'Bearer 8e85a864f0da24dd1dedf78f1c7b6896bbbbbdb536bf4f2078f35007ff666bc1'
}
conn.request("GET", "/public/v2/users", payload, headers)
res = conn.getresponse()
data = res.read()
print(data.decode("utf-8"))

import requests
import json
import pandas as pd

url = "https://gorest.co.in/public/v2/graphql"

payload = "{\"query\":\"query{users {pageInfo {endCursor startCursor hasNextPage hasPreviousPage} totalCount nodes {id name email gender status}}}\",\"variables\":{}}"
headers = {
  'Accept': 'application/json',
  'Content-Type': 'application/json',
  'Authorization': 'Bearer ACCESS-TOKEN'
}

response = requests.request("POST", url, headers=headers, data=payload)

response.json()

df2 = pd.DataFrame(response.json()['data']['users']['nodes'])
df2.head()

"""Scrapping Request"""

import requests
import pandas as pd

url = 'https://datausa.io/api/data?drilldowns=Nation&measures=Population'
response = requests.get(url)
data = response.json()

df = pd.DataFrame(data['data'])
df.head()

"""Scrap with b4"""

from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://www.detik.com/terpopuler'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

list_content = soup.select('article')

list_content[0]

result = []
for item in list_content:
  data = dict()

  data['title'] = item.select_one('.media__title').text
  data['link'] = item.select_one('.media__title').a['href']
  result.append(data)

  pd.DataFrame(result)